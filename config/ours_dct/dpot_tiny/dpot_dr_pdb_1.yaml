seed: 1
algorithm: dct
net: dpot2d
dataset: dr_pdb
save_name: dpot_dr_pdb_1
save_dir: ./saved_models/ours_dct/dpot_tiny/
load_path: ./saved_models/ours_dct/dpot_tiny/dpot_dr_pdb_1/latest_model.pth
# 
resume: false
overwrite: true
use_tensorboard: false
dataset_type: temporal
normalize: false
# FOR DATASET CONFIGURATIONS
img_size: 128, 128
res: 128
n_channels: 2
T_in: 2
T_ar: 5
T_bundle: 1
noise_scale: 0.0
# noise_scale: 0.0005
# FOR OPTIMIZATION CONFIGURATIONS
epochs: 500
num_train_iter: 32000
num_eval_iter: 64
num_log_iter: 16
batch_size: 128
eval_batch_size: 128
# 
optim: adamw
beta1: 0.9
beta2: 0.999
# 
clip_grad: 5.0
warmup_epochs: 50
weight_decay: 1e-6
lr: 0.0005
lr_method: cycle
# FOR TRAINING CONFIGURATIONS
train_sampler: RandomSampler
num_workers: 8
world_size: 1
rank: 0
multiprocessing_distributed: false
dist_url: tcp://127.0.0.1:22647
dist_backend: nccl
gpu: None
# DPOT SPECIFIC CONFIGURATIONS
patch_size: 8
width: 512
mlp_ratio: 1
n_blocks: 4
n_layers: 4
modes: 32
out_layer_dim: 32
act: gelu
mixing_type: afno
time_agg: exp_mlp
use_ln: false
# FOR ADDITIONAL TRAINING CONFIGURATIONS
use_tf: ture
# use_tf: false
use_dcm: true
# use_dcm: false
use_sampler: false