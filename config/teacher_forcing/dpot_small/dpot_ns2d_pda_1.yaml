seed: 1
algorithm: standard_mse
net: dpot2d
dataset: ns2d_pda
save_name: dpot_ns2d_pda_1
save_dir: ./saved_models/teacher_forcing/dpot_small/
load_path: ./saved_models/teacher_forcing/dpot_small/dpot_ns2d_pda_1/latest_model.pth
# 
resume: false
overwrite: true
use_tensorboard: false
dataset_type: temporal
normalize: false
# FOR DATASET CONFIGURATIONS
img_size: 128, 128
res: 128
n_channels: 3
T_in: 10
T_ar: 4
T_bundle: 1
noise_scale: 0.0
# noise_scale: 0.0005
# FOR OPTIMIZATION CONFIGURATIONS
epochs: 500
num_train_iter: 100000
num_eval_iter: 200
num_log_iter: 50
batch_size: 32
eval_batch_size: 32
# 
optim: adamw
beta1: 0.9
beta2: 0.999
# 
clip_grad: 5.0
warmup_epochs: 50
weight_decay: 1e-6
lr: 0.001
lr_method: cycle
# FOR TRAINING CONFIGURATIONS
train_sampler: RandomSampler
num_workers: 8
world_size: 1
rank: 0
multiprocessing_distributed: false
dist_url: tcp://127.0.0.1:22647
dist_backend: nccl
gpu: None
# DPOT SPECIFIC CONFIGURATIONS
patch_size: 8
width: 1024
mlp_ratio: 1
n_blocks: 8
n_layers: 6
modes: 32
out_layer_dim: 32
act: gelu
mixing_type: afno
time_agg: exp_mlp
use_ln: false
# FOR ADDITIONAL TRAINING CONFIGURATIONS
use_tf: ture
# use_tf: false
use_dcm: false
use_sampler: false